{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m2ToNpp-HPfb"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69MD6waHeWn",
        "outputId": "186fd95b-048c-4e40-f220-9b17a1accfa0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8us1YpcH0zK",
        "outputId": "05eafcd5-3b76-4ac6-8813-e6b5c572535b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ne3D9vDH2Um",
        "outputId": "91a6438a-3051-4959-cecd-7a2933482ab9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "BYUW_LRyH5Db"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text:\", text[:13])\n",
        "print(\"Encoded:\", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHW0qYwH89y",
        "outputId": "0b25413d-305d-42d2-bcd3-dd0d7131c339"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUDG7HXRH_LH",
        "outputId": "4712c7bc-c2df-4d15-87f9-ac475db422d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "yaO1uYQTIGZ_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "cpDuujFrIJN_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsytaqoeIK1g",
        "outputId": "29d43b0c-ee00-4597-ad8c-4e6637b0fe16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Vwsj3PWfIgTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "GUjICzIrIz1q",
        "outputId": "4fe70afc-1c66-4bac-8637-6afe2d236839"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EyyN1fbI7F4",
        "outputId": "5f65a886-653b-463d-faa8-4ab722f32301"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmcyqNV7JHzy",
        "outputId": "ef335a11-10fb-4afd-e3b2-8d73092fc3bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 5.46729832e-04  7.41950935e-04 -5.43905701e-03 ...  3.00657796e-03\n",
            "    1.57341175e-03  1.71764963e-03]\n",
            "  [-5.86823607e-03  9.29657894e-04  3.66302498e-04 ...  5.33052627e-03\n",
            "    2.95066333e-04 -4.90337657e-03]\n",
            "  [ 2.17773672e-03  2.17570621e-03  4.27259738e-03 ...  3.46313836e-03\n",
            "    2.92041013e-03 -4.99127479e-03]\n",
            "  ...\n",
            "  [ 3.44167277e-03 -7.69976899e-03  2.61976197e-03 ...  3.53078358e-03\n",
            "   -1.07914628e-02  3.55802523e-03]\n",
            "  [ 3.57957208e-04 -5.63974399e-03  4.45354171e-03 ...  6.41012099e-04\n",
            "   -8.73361342e-03  2.99073989e-04]\n",
            "  [-6.20317645e-03 -5.77627029e-03  8.76121782e-03 ...  4.48932359e-03\n",
            "   -6.54788036e-03 -5.02902037e-03]]\n",
            "\n",
            " [[-1.91156229e-03 -4.38543595e-03 -1.49552524e-03 ...  2.51645059e-03\n",
            "    8.28294782e-04  1.82810496e-03]\n",
            "  [-6.94392109e-03 -1.40007259e-03 -2.89825164e-03 ...  3.41509841e-03\n",
            "    2.65887217e-03  3.67767410e-03]\n",
            "  [-9.67427157e-03 -5.01240883e-03  3.37761012e-04 ...  7.88868591e-03\n",
            "    2.65447190e-03  6.88262330e-03]\n",
            "  ...\n",
            "  [-9.85087268e-03 -2.51297490e-03 -3.81902023e-03 ... -3.95851070e-03\n",
            "   -7.80129386e-03  5.48698381e-03]\n",
            "  [-1.03774518e-02 -6.41562557e-03 -6.39257813e-03 ... -2.45002564e-03\n",
            "   -7.49774277e-03  1.08850952e-02]\n",
            "  [-1.36256153e-02 -6.77834544e-03 -2.95431539e-03 ...  3.85875057e-04\n",
            "   -6.44944375e-03  2.38484703e-03]]\n",
            "\n",
            " [[-2.35747825e-03 -7.02608610e-03 -4.46653645e-03 ...  1.84860360e-03\n",
            "   -3.01273493e-03 -1.99293788e-03]\n",
            "  [-8.12867563e-03 -5.36340848e-03  3.18843668e-04 ...  3.89754050e-03\n",
            "   -3.07458173e-03 -6.81088120e-03]\n",
            "  [-5.95671078e-03 -2.96400464e-03 -5.28666889e-03 ...  5.03055518e-03\n",
            "   -2.98212661e-04 -2.58286367e-03]\n",
            "  ...\n",
            "  [ 1.55749114e-03 -1.35358125e-02 -1.37584039e-03 ... -7.39175593e-04\n",
            "   -4.17020777e-03  4.01316117e-03]\n",
            "  [-5.06589655e-03 -1.17742456e-02  1.00615912e-03 ...  2.19233264e-03\n",
            "   -4.61310707e-03 -1.73425686e-03]\n",
            "  [-7.63063272e-03 -1.23884715e-02  1.43290125e-03 ...  6.17554318e-03\n",
            "   -3.53865628e-03  2.67694076e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 2.46520666e-03  6.11361349e-03  3.06444708e-03 ... -6.04633428e-03\n",
            "    3.92854726e-03 -2.77720671e-03]\n",
            "  [-3.18873324e-03  6.67688018e-03  4.68389364e-03 ... -7.03698536e-03\n",
            "    7.85006303e-03 -1.78416923e-03]\n",
            "  [ 1.29763479e-03  1.66070147e-03  3.19299335e-03 ... -3.32917972e-03\n",
            "    5.07368194e-03 -1.08926499e-03]\n",
            "  ...\n",
            "  [ 3.76034365e-03 -9.32441372e-03  2.89029442e-03 ... -1.83439546e-03\n",
            "    1.33820681e-03 -2.41475552e-03]\n",
            "  [-7.53928325e-04 -1.14335865e-02  7.76215631e-04 ... -1.08033547e-03\n",
            "   -1.13470876e-03  5.21754520e-03]\n",
            "  [-4.07068012e-03 -1.10764252e-02 -2.31129746e-03 ... -2.27595842e-03\n",
            "   -3.03583825e-03  2.69560842e-03]]\n",
            "\n",
            " [[ 5.09451516e-03 -8.31770070e-04  5.62903425e-03 ... -4.47068783e-03\n",
            "   -3.58544115e-04 -4.77970578e-03]\n",
            "  [ 5.30531676e-03 -4.86701680e-03  2.67382385e-03 ... -2.51968100e-04\n",
            "   -5.70425938e-04 -1.37774763e-03]\n",
            "  [ 1.17148710e-02 -3.74433352e-03  5.70161082e-03 ... -3.80492827e-04\n",
            "    3.13465646e-03 -1.42525020e-03]\n",
            "  ...\n",
            "  [-1.19368024e-02 -1.14446674e-02  1.68123271e-03 ...  9.28928144e-03\n",
            "    3.53237754e-03  1.07489375e-03]\n",
            "  [-7.71716237e-03 -9.52957664e-03 -1.52896205e-03 ...  8.37144163e-03\n",
            "    1.82972034e-03  2.97620194e-04]\n",
            "  [-4.85456316e-03 -8.20792653e-03 -6.26984611e-03 ...  8.90753884e-03\n",
            "    2.37778667e-03  2.95997621e-03]]\n",
            "\n",
            " [[-2.58257426e-03 -6.23210217e-04 -1.90853234e-03 ...  1.67010049e-03\n",
            "    4.22027009e-03  1.75772875e-03]\n",
            "  [ 2.26991088e-03 -2.30933237e-03  5.26519667e-04 ...  7.54542765e-04\n",
            "   -9.28750320e-04  9.85315070e-04]\n",
            "  [ 4.22065787e-04 -5.94055466e-03  1.59467605e-03 ... -9.56476943e-05\n",
            "   -2.11170060e-03  1.65905396e-03]\n",
            "  ...\n",
            "  [ 1.05960178e-03 -1.42838003e-03  5.32862544e-03 ... -3.67454835e-04\n",
            "    1.43238960e-03 -4.67248773e-03]\n",
            "  [-3.48532060e-03 -8.06267373e-03 -7.68114871e-04 ...  1.35238777e-04\n",
            "   -1.60856824e-03 -4.31734836e-03]\n",
            "  [-1.00936117e-02 -6.07404299e-03  2.73446320e-03 ...  1.50724070e-03\n",
            "   -1.79156440e-03 -7.57682137e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irax_4_4JW3d",
        "outputId": "8a218281-cef0-48b3-d824-6ba895ebc927"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 0.00054673  0.00074195 -0.00543906 ...  0.00300658  0.00157341\n",
            "   0.00171765]\n",
            " [-0.00586824  0.00092966  0.0003663  ...  0.00533053  0.00029507\n",
            "  -0.00490338]\n",
            " [ 0.00217774  0.00217571  0.0042726  ...  0.00346314  0.00292041\n",
            "  -0.00499127]\n",
            " ...\n",
            " [ 0.00344167 -0.00769977  0.00261976 ...  0.00353078 -0.01079146\n",
            "   0.00355803]\n",
            " [ 0.00035796 -0.00563974  0.00445354 ...  0.00064101 -0.00873361\n",
            "   0.00029907]\n",
            " [-0.00620318 -0.00577627  0.00876122 ...  0.00448932 -0.00654788\n",
            "  -0.00502902]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeIjf0sOJXgl",
        "outputId": "18972738-e22c-4755-a41b-3db8c0103df2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 5.4672983e-04  7.4195093e-04 -5.4390570e-03 -3.6077448e-03\n",
            "  4.7703357e-05 -3.0778986e-03  1.2298357e-03  8.5867178e-03\n",
            " -2.8979824e-05 -2.0733692e-03  2.2469151e-03  2.7372208e-03\n",
            " -4.5727440e-03 -6.1822166e-03  5.6347335e-03 -6.4780042e-03\n",
            " -1.4981368e-03 -4.2473315e-03 -6.8715340e-03  7.4205577e-04\n",
            "  8.0974615e-04 -7.0028906e-03 -6.6542812e-04 -8.1322120e-05\n",
            " -1.4590849e-03  3.0104632e-03 -5.8698014e-04  5.9225801e-03\n",
            " -6.3152015e-03 -2.9143582e-03 -7.6319629e-05 -2.2738036e-03\n",
            " -1.8678951e-03 -1.0015913e-03  1.3279354e-03 -1.4485371e-03\n",
            "  6.7552151e-03 -1.4432193e-03 -3.3720999e-03 -5.9255832e-03\n",
            " -5.4084943e-03  7.6772799e-03 -9.3590264e-04  7.3791138e-04\n",
            " -2.9151833e-03 -9.6841430e-04 -3.4587011e-03 -1.0307385e-02\n",
            " -7.8002216e-05 -1.9191904e-03  1.2375545e-03  4.6493500e-04\n",
            "  1.7275227e-03  1.1511173e-03 -3.4073191e-03 -1.2087051e-03\n",
            "  2.8767814e-03  1.1176458e-02  4.7900300e-03 -2.3786162e-03\n",
            "  2.7159341e-03 -5.1799137e-04  3.0065780e-03  1.5734117e-03\n",
            "  1.7176496e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DQYO0FIIJeAE",
        "outputId": "e8d69cef-1ddd-4814-db35-d3317a11febd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"yp-LKSoAULt.-NeEMMW$Z!OeY3BX3or-oesEk'jbodOvWnnsJf'LWpyddIYhG?&qCxErWaTRfbRgXIte:Lvq&MzWW g uQN\\nuDBO\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "lOHK9swxJkWB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "f8bhKqOzJmnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "Bb-IWqF4Jpor"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcaVBidvJy0g",
        "outputId": "4833cedd-ae12-4d9e-d6ae-c4b92a0a4d32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - loss: 2.8500\n",
            "Epoch 2/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.8343\n",
            "Epoch 3/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 1.5897\n",
            "Epoch 4/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - loss: 1.4663\n",
            "Epoch 5/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 1.3916\n",
            "Epoch 6/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 1.3414\n",
            "Epoch 7/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 1.2981\n",
            "Epoch 8/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 1.2637\n",
            "Epoch 9/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.2319\n",
            "Epoch 10/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.1963\n",
            "Epoch 11/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 1.1649\n",
            "Epoch 12/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.1309\n",
            "Epoch 13/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.1000\n",
            "Epoch 14/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.0671\n",
            "Epoch 15/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.0320\n",
            "Epoch 16/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 0.9961\n",
            "Epoch 17/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.9592\n",
            "Epoch 18/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.9238\n",
            "Epoch 19/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.8882\n",
            "Epoch 20/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.8532\n",
            "Epoch 21/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - loss: 0.8203\n",
            "Epoch 22/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.7880\n",
            "Epoch 23/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.7552\n",
            "Epoch 24/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.7258\n",
            "Epoch 25/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.6980\n",
            "Epoch 26/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 0.6728\n",
            "Epoch 27/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.6456\n",
            "Epoch 28/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.6248\n",
            "Epoch 29/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 0.6029\n",
            "Epoch 30/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.5849\n",
            "Epoch 31/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.5697\n",
            "Epoch 32/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - loss: 0.5535\n",
            "Epoch 33/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.5359\n",
            "Epoch 34/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - loss: 0.5240\n",
            "Epoch 35/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.5151\n",
            "Epoch 36/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.5044\n",
            "Epoch 37/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.4930\n",
            "Epoch 38/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 0.4837\n",
            "Epoch 39/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.4771\n",
            "Epoch 40/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - loss: 0.4692\n",
            "Epoch 41/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - loss: 0.4600\n",
            "Epoch 42/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - loss: 0.4532\n",
            "Epoch 43/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.4469\n",
            "Epoch 44/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.4445\n",
            "Epoch 45/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - loss: 0.4398\n",
            "Epoch 46/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - loss: 0.4351\n",
            "Epoch 47/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - loss: 0.4306\n",
            "Epoch 48/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.4230\n",
            "Epoch 49/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.4231\n",
            "Epoch 50/50\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - loss: 0.4206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "CXYl-JcwNG0S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint_file:\n",
        "    print(f\"Found latest checkpoint: {latest_checkpoint_file}\")\n",
        "    model.build(tf.TensorShape([1, None])) # Build the model before loading weights\n",
        "    model.load_weights(latest_checkpoint_file)\n",
        "else:\n",
        "    manual_checkpoint_path = os.path.join(checkpoint_dir, 'ckpt_50.weights.h5') # Assuming ckpt_50.weights.h5 exists based on the previous output\n",
        "    if os.path.exists(manual_checkpoint_path):\n",
        "        print(f\"Loading weights from: {manual_checkpoint_path}\")\n",
        "        model.build(tf.TensorShape([1, None])) # Build the model before loading weights\n",
        "        model.load_weights(manual_checkpoint_path)\n",
        "    else:\n",
        "        print(f\"Error: Could not find latest checkpoint or specific file: {manual_checkpoint_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yen0ART4NJc5",
        "outputId": "1f006783-ca46-483a-e8e9-63509d2525b3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from: ./training_checkpoints/ckpt_50.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5767fef4"
      },
      "source": [
        "model.build(tf.TensorShape([1, None]))\n",
        "model.load_weights(\"./training_checkpoints/ckpt_50.weights.h5\") # Correct usage for .h5 files"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 800\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "\n",
        "  model.layers[1].reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "8_cskgEmT5uR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT6l5aNyT9iv",
        "outputId": "a0e2c0ef-eeca-48b6-931c-80976ae77154"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: perchance\n",
            "perchance of the king.\n",
            "\n",
            "GLOUCESTER:\n",
            "Nay, hence, good Morth, and know no holy a man's hounds;\n",
            "Knew me so old as you are early in being,\n",
            "And make my mind to death, my lord of Claudio;\n",
            "So thrive I in my author, but a lord.\n",
            "\n",
            "PAGE:\n",
            "Are you man that doth not these\n",
            "words please, as his head upon the gaol.\n",
            "Could we be satisfied! England's death, clapp'd our curbing face;\n",
            "For I have fearful to thy lord.\n",
            "\n",
            "GLOUCESTER:\n",
            "No doubt, no doubt; O, 'tis a part, and good nurse, here comes the French\n",
            "And none away to ve one of the other: who should keeps him,\n",
            "He hurling so blind,\n",
            "That with upright traitor to the party, having advantage of his worth\n",
            "and unspark'd that hath devour'd the realmy: and now about\n",
            "More than to stand in narrow tander\n",
            "Asher my bold's vault,\n",
            "That makes his feether than I looked anyour honour.\n",
            "\n",
            "IS\n"
          ]
        }
      ]
    }
  ]
}